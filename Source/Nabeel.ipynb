{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import json\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a recommendation system. Usage of surprise package. Using the k-NN Baseline algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small size for testing\n",
    "db_dev_path = 'netflix_dev.db'\n",
    "db_dev_conn = 'sqlite://' + db_dev_path\n",
    "\n",
    "# full size for production\n",
    "db_prod_path = 'netflix.db'\n",
    "db_prod_conn = 'sqlite://' + db_prod_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data = pl.read_database(\"SELECT * FROM netflix_data\", db_dev_conn)\n",
    "movie_titles = pl.read_database(\"SELECT * FROM movie_titles\", db_dev_conn)\n",
    "# combined     = pl.read_database(\"SELECT * FROM netflix_data, movie_titles \\\n",
    "#                                   WHERE netflix_data.film = movie_titles.film\", db_prod_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data = pl.read_database(\"SELECT * FROM netflix_data\", db_dev_conn)\n",
    "movie_titles = pl.read_database(\"SELECT * FROM movie_titles\", db_dev_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of ratings\n",
    "len(netflix_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the title for a given item_id (column film)\n",
    "# i.e. get_title(16242) -> \"Con Air\"\n",
    "def get_title(item_id):\n",
    "    return movie_titles.filter(pl.col(\"film\") == item_id)[\"title\"].to_list()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- most_rated hat die 100 most rated Filme\n",
    "- best_rated hat die 100 best rated Filme\n",
    "- not_rated Filme die kein rating haben\n",
    "- rated hat Filme mit mind 1 rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>film</th><th>num_ratings</th><th>avg_rating</th></tr><tr><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>5317</td><td>232944</td><td>3.361267</td></tr><tr><td>15124</td><td>216596</td><td>3.724238</td></tr><tr><td>14313</td><td>200832</td><td>3.783854</td></tr><tr><td>15205</td><td>196397</td><td>3.442166</td></tr><tr><td>1905</td><td>193941</td><td>4.153908</td></tr><tr><td>6287</td><td>193295</td><td>3.905047</td></tr><tr><td>11283</td><td>181508</td><td>4.29991</td></tr><tr><td>16377</td><td>181426</td><td>4.306941</td></tr><tr><td>16242</td><td>178068</td><td>3.454411</td></tr><tr><td>12470</td><td>177556</td><td>3.41187</td></tr><tr><td>15582</td><td>176539</td><td>3.538589</td></tr><tr><td>9340</td><td>173596</td><td>3.39797</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>14149</td><td>119653</td><td>3.770578</td></tr><tr><td>13462</td><td>118884</td><td>3.35972</td></tr><tr><td>8387</td><td>118880</td><td>3.587778</td></tr><tr><td>30</td><td>118413</td><td>3.761842</td></tr><tr><td>10042</td><td>118212</td><td>4.504035</td></tr><tr><td>16882</td><td>117314</td><td>3.136147</td></tr><tr><td>3282</td><td>117270</td><td>3.434723</td></tr><tr><td>11337</td><td>116767</td><td>3.740012</td></tr><tr><td>457</td><td>116762</td><td>3.874386</td></tr><tr><td>6844</td><td>116716</td><td>3.250497</td></tr><tr><td>10583</td><td>116609</td><td>3.549349</td></tr><tr><td>3151</td><td>116362</td><td>3.3983</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 3)\n",
       "┌───────┬─────────────┬────────────┐\n",
       "│ film  ┆ num_ratings ┆ avg_rating │\n",
       "│ ---   ┆ ---         ┆ ---        │\n",
       "│ i64   ┆ i64         ┆ f64        │\n",
       "╞═══════╪═════════════╪════════════╡\n",
       "│ 5317  ┆ 232944      ┆ 3.361267   │\n",
       "│ 15124 ┆ 216596      ┆ 3.724238   │\n",
       "│ 14313 ┆ 200832      ┆ 3.783854   │\n",
       "│ 15205 ┆ 196397      ┆ 3.442166   │\n",
       "│ …     ┆ …           ┆ …          │\n",
       "│ 457   ┆ 116762      ┆ 3.874386   │\n",
       "│ 6844  ┆ 116716      ┆ 3.250497   │\n",
       "│ 10583 ┆ 116609      ┆ 3.549349   │\n",
       "│ 3151  ┆ 116362      ┆ 3.3983     │\n",
       "└───────┴─────────────┴────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_rated = pl.read_database(\"SELECT netflix_data.film, COUNT(*) AS 'num_ratings', AVG(netflix_data.rating) AS 'avg_rating' \\\n",
    "                               FROM netflix_data \\\n",
    "                               GROUP BY netflix_data.film \\\n",
    "                               ORDER BY num_ratings DESC \\\n",
    "                               LIMIT 100 \\\n",
    "                               \", db_prod_conn)\n",
    "\n",
    "most_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (665, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>film</th><th>user</th><th>rating</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>15205</td><td>2523958</td><td>4</td></tr><tr><td>5317</td><td>843821</td><td>4</td></tr><tr><td>15124</td><td>65908</td><td>4</td></tr><tr><td>5317</td><td>191646</td><td>3</td></tr><tr><td>15124</td><td>2255575</td><td>5</td></tr><tr><td>15124</td><td>465480</td><td>4</td></tr><tr><td>15205</td><td>142234</td><td>3</td></tr><tr><td>5317</td><td>2564388</td><td>3</td></tr><tr><td>15205</td><td>52203</td><td>3</td></tr><tr><td>15205</td><td>1091345</td><td>4</td></tr><tr><td>15205</td><td>1250371</td><td>3</td></tr><tr><td>15205</td><td>715748</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>15205</td><td>2004647</td><td>3</td></tr><tr><td>15124</td><td>1408227</td><td>1</td></tr><tr><td>15124</td><td>602787</td><td>2</td></tr><tr><td>15124</td><td>427135</td><td>3</td></tr><tr><td>5317</td><td>251969</td><td>3</td></tr><tr><td>15124</td><td>1081799</td><td>4</td></tr><tr><td>5317</td><td>1794919</td><td>3</td></tr><tr><td>5317</td><td>983069</td><td>5</td></tr><tr><td>5317</td><td>1497281</td><td>3</td></tr><tr><td>5317</td><td>965378</td><td>5</td></tr><tr><td>5317</td><td>2271375</td><td>3</td></tr><tr><td>15205</td><td>749553</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (665, 3)\n",
       "┌───────┬─────────┬────────┐\n",
       "│ film  ┆ user    ┆ rating │\n",
       "│ ---   ┆ ---     ┆ ---    │\n",
       "│ i64   ┆ i64     ┆ i64    │\n",
       "╞═══════╪═════════╪════════╡\n",
       "│ 15205 ┆ 2523958 ┆ 4      │\n",
       "│ 5317  ┆ 843821  ┆ 4      │\n",
       "│ 15124 ┆ 65908   ┆ 4      │\n",
       "│ 5317  ┆ 191646  ┆ 3      │\n",
       "│ …     ┆ …       ┆ …      │\n",
       "│ 5317  ┆ 1497281 ┆ 3      │\n",
       "│ 5317  ┆ 965378  ┆ 5      │\n",
       "│ 5317  ┆ 2271375 ┆ 3      │\n",
       "│ 15205 ┆ 749553  ┆ 5      │\n",
       "└───────┴─────────┴────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove movies with less than 100 ratings\n",
    "# get the number of ratings for each movie\n",
    "pre_ratings = netflix_data.groupby(\"film\").count()\n",
    "\n",
    "# keep only movies with at least 100 ratings\n",
    "pre_ratings = pre_ratings.filter(pl.col(\"count\") >= 200)\n",
    "\n",
    "# join the dataframes\n",
    "pre_ratings = netflix_data.join(pre_ratings, on=\"film\", how=\"inner\")\n",
    "\n",
    "# bring the ratings into a format that surprise can work with\n",
    "ratings = pre_ratings.drop(\"date\").drop(\"count\")\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average rating for each user\n",
    "avg_rating_user = ratings.groupby(\"user\").mean().sort(pl.col(\"rating\")).drop(\"film\")\n",
    "\n",
    "# average rating for each movie\n",
    "avg_rating_film = ratings.groupby(\"film\").mean().sort(pl.col(\"rating\")).drop(\"user\")\n",
    "\n",
    "# Count of ratings for each movie\n",
    "film_rating_counts = ratings.groupby(\"film\").agg(\n",
    "    [\n",
    "        pl.count(\"rating\").alias(\"count\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Count of ratings for each user\n",
    "user_rating_counts = ratings.groupby(\"user\").agg(\n",
    "    [\n",
    "        pl.count(\"rating\").alias(\"count\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "avg_rating_film = avg_rating_film.join(film_rating_counts, on=\"film\")\n",
    "avg_rating_user = avg_rating_user.join(user_rating_counts, on=\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Response</th>\n",
       "      <th>Rated</th>\n",
       "      <th>Released</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Director</th>\n",
       "      <th>Writer</th>\n",
       "      <th>...</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>imdbID</th>\n",
       "      <th>Type</th>\n",
       "      <th>DVD</th>\n",
       "      <th>BoxOffice</th>\n",
       "      <th>Production</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>2003–</td>\n",
       "      <td>True</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>14 Dec 2003</td>\n",
       "      <td>50 min</td>\n",
       "      <td>Documentary, Animation, Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Source': 'Internet Movie Database', 'Value'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7</td>\n",
       "      <td>531</td>\n",
       "      <td>tt0389605</td>\n",
       "      <td>series</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Character</td>\n",
       "      <td>1997</td>\n",
       "      <td>True</td>\n",
       "      <td>R</td>\n",
       "      <td>27 Mar 1998</td>\n",
       "      <td>122 min</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>Mike van Diem</td>\n",
       "      <td>Ferdinand Bordewijk, Laurens Geels, Mike van Diem</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Source': 'Internet Movie Database', 'Value'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7</td>\n",
       "      <td>11,037</td>\n",
       "      <td>tt0119448</td>\n",
       "      <td>movie</td>\n",
       "      <td>04 Feb 2003</td>\n",
       "      <td>$623,983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sick</td>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>R</td>\n",
       "      <td>13 Jan 2023</td>\n",
       "      <td>83 min</td>\n",
       "      <td>Horror, Thriller</td>\n",
       "      <td>John Hyams</td>\n",
       "      <td>Kevin Williamson, Katelyn Crabb</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Source': 'Internet Movie Database', 'Value'...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12,303</td>\n",
       "      <td>tt14642626</td>\n",
       "      <td>movie</td>\n",
       "      <td>13 Jan 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What the #$*! Do We Know!?</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04 Oct 2017</td>\n",
       "      <td>97 min</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Kip Andersen, Keegan Kuhn</td>\n",
       "      <td>Kip Andersen, Keegan Kuhn</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Source': 'Internet Movie Database', 'Value'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>29,844</td>\n",
       "      <td>tt5541848</td>\n",
       "      <td>movie</td>\n",
       "      <td>16 Jun 2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>9230</td>\n",
       "      <td>Shakespeare in Love</td>\n",
       "      <td>1998</td>\n",
       "      <td>True</td>\n",
       "      <td>R</td>\n",
       "      <td>08 Jan 1999</td>\n",
       "      <td>123 min</td>\n",
       "      <td>Comedy, Drama, History</td>\n",
       "      <td>John Madden</td>\n",
       "      <td>Marc Norman, Tom Stoppard</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Source': 'Internet Movie Database', 'Value'...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>228,514</td>\n",
       "      <td>tt0138097</td>\n",
       "      <td>movie</td>\n",
       "      <td>07 Dec 1999</td>\n",
       "      <td>$100,317,794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>9231</td>\n",
       "      <td>Fidel Castro: American Experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>9232</td>\n",
       "      <td>Epoch</td>\n",
       "      <td>2001</td>\n",
       "      <td>True</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>24 Nov 2001</td>\n",
       "      <td>96 min</td>\n",
       "      <td>Sci-Fi, Thriller</td>\n",
       "      <td>Matt Codd</td>\n",
       "      <td>Jonathan Raymond, Phillip J. Roth</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Source': 'Internet Movie Database', 'Value'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2,474</td>\n",
       "      <td>tt0233657</td>\n",
       "      <td>movie</td>\n",
       "      <td>25 Aug 2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9233</th>\n",
       "      <td>9233</td>\n",
       "      <td>The Company</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>07 May 2004</td>\n",
       "      <td>112 min</td>\n",
       "      <td>Drama, Music, Romance</td>\n",
       "      <td>Robert Altman</td>\n",
       "      <td>Neve Campbell, Barbara Turner</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Source': 'Internet Movie Database', 'Value'...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6,708</td>\n",
       "      <td>tt0335013</td>\n",
       "      <td>movie</td>\n",
       "      <td>01 Jun 2004</td>\n",
       "      <td>$2,283,914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9234</th>\n",
       "      <td>9234</td>\n",
       "      <td>Alien Hunter</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>R</td>\n",
       "      <td>19 Jul 2003</td>\n",
       "      <td>92 min</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "      <td>Ron Krauss</td>\n",
       "      <td>J.S. Cardone, Boaz Davidson</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'Source': 'Internet Movie Database', 'Value'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4,626</td>\n",
       "      <td>tt0327409</td>\n",
       "      <td>movie</td>\n",
       "      <td>28 Oct 2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9235 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                              Title   Year  Response  \\\n",
       "0              0                    Dinosaur Planet  2003–      True   \n",
       "1              1         Isle of Man TT 2004 Review    NaN     False   \n",
       "2              2                          Character   1997      True   \n",
       "3              3                               Sick   2022      True   \n",
       "4              4         What the #$*! Do We Know!?   2017      True   \n",
       "...          ...                                ...    ...       ...   \n",
       "9230        9230                Shakespeare in Love   1998      True   \n",
       "9231        9231  Fidel Castro: American Experience    NaN     False   \n",
       "9232        9232                              Epoch   2001      True   \n",
       "9233        9233                        The Company   2003      True   \n",
       "9234        9234                       Alien Hunter   2003      True   \n",
       "\n",
       "          Rated     Released  Runtime                           Genre  \\\n",
       "0     Not Rated  14 Dec 2003   50 min  Documentary, Animation, Family   \n",
       "1           NaN          NaN      NaN                             NaN   \n",
       "2             R  27 Mar 1998  122 min           Crime, Drama, Mystery   \n",
       "3             R  13 Jan 2023   83 min                Horror, Thriller   \n",
       "4           NaN  04 Oct 2017   97 min                     Documentary   \n",
       "...         ...          ...      ...                             ...   \n",
       "9230          R  08 Jan 1999  123 min          Comedy, Drama, History   \n",
       "9231        NaN          NaN      NaN                             NaN   \n",
       "9232      PG-13  24 Nov 2001   96 min                Sci-Fi, Thriller   \n",
       "9233      PG-13  07 May 2004  112 min           Drama, Music, Romance   \n",
       "9234          R  19 Jul 2003   92 min       Action, Adventure, Sci-Fi   \n",
       "\n",
       "                       Director  \\\n",
       "0                           NaN   \n",
       "1                           NaN   \n",
       "2                 Mike van Diem   \n",
       "3                    John Hyams   \n",
       "4     Kip Andersen, Keegan Kuhn   \n",
       "...                         ...   \n",
       "9230                John Madden   \n",
       "9231                        NaN   \n",
       "9232                  Matt Codd   \n",
       "9233              Robert Altman   \n",
       "9234                 Ron Krauss   \n",
       "\n",
       "                                                 Writer  ...  \\\n",
       "0                                                   NaN  ...   \n",
       "1                                                   NaN  ...   \n",
       "2     Ferdinand Bordewijk, Laurens Geels, Mike van Diem  ...   \n",
       "3                       Kevin Williamson, Katelyn Crabb  ...   \n",
       "4                             Kip Andersen, Keegan Kuhn  ...   \n",
       "...                                                 ...  ...   \n",
       "9230                          Marc Norman, Tom Stoppard  ...   \n",
       "9231                                                NaN  ...   \n",
       "9232                  Jonathan Raymond, Phillip J. Roth  ...   \n",
       "9233                      Neve Campbell, Barbara Turner  ...   \n",
       "9234                        J.S. Cardone, Boaz Davidson  ...   \n",
       "\n",
       "                                                Ratings Metascore imdbRating  \\\n",
       "0     [{'Source': 'Internet Movie Database', 'Value'...       NaN        7.7   \n",
       "1                                                   NaN       NaN        NaN   \n",
       "2     [{'Source': 'Internet Movie Database', 'Value'...       NaN        7.7   \n",
       "3     [{'Source': 'Internet Movie Database', 'Value'...      62.0        6.1   \n",
       "4     [{'Source': 'Internet Movie Database', 'Value'...       NaN        7.2   \n",
       "...                                                 ...       ...        ...   \n",
       "9230  [{'Source': 'Internet Movie Database', 'Value'...      87.0        7.1   \n",
       "9231                                                NaN       NaN        NaN   \n",
       "9232  [{'Source': 'Internet Movie Database', 'Value'...       NaN        4.8   \n",
       "9233  [{'Source': 'Internet Movie Database', 'Value'...      73.0        6.2   \n",
       "9234  [{'Source': 'Internet Movie Database', 'Value'...       NaN        5.1   \n",
       "\n",
       "     imdbVotes      imdbID    Type          DVD     BoxOffice  Production  \\\n",
       "0          531   tt0389605  series          NaN           NaN         NaN   \n",
       "1          NaN         NaN     NaN          NaN           NaN         NaN   \n",
       "2       11,037   tt0119448   movie  04 Feb 2003      $623,983         NaN   \n",
       "3       12,303  tt14642626   movie  13 Jan 2023           NaN         NaN   \n",
       "4       29,844   tt5541848   movie  16 Jun 2017           NaN         NaN   \n",
       "...        ...         ...     ...          ...           ...         ...   \n",
       "9230   228,514   tt0138097   movie  07 Dec 1999  $100,317,794         NaN   \n",
       "9231       NaN         NaN     NaN          NaN           NaN         NaN   \n",
       "9232     2,474   tt0233657   movie  25 Aug 2005           NaN         NaN   \n",
       "9233     6,708   tt0335013   movie  01 Jun 2004    $2,283,914         NaN   \n",
       "9234     4,626   tt0327409   movie  28 Oct 2003           NaN         NaN   \n",
       "\n",
       "     Website  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "...      ...  \n",
       "9230     NaN  \n",
       "9231     NaN  \n",
       "9232     NaN  \n",
       "9233     NaN  \n",
       "9234     NaN  \n",
       "\n",
       "[9235 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data = pd.read_csv(\"data/movie_data.csv\", sep=\"|\")\n",
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['film', 'user', 'rating'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m reader \u001b[39m=\u001b[39m Reader(rating_scale\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[39m# Lade den DataFrame in einen Surprise-Datensatz\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m data \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mload_from_df(movie_data[[\u001b[39m'\u001b[39;49m\u001b[39mfilm\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m]], reader)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Teile den Datensatz in Trainings- und Testdaten auf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m trainset \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mbuild_full_trainset()\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['film', 'user', 'rating'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Annahme: Der Netflix-Datensatz ist als DataFrame namens \"netflix_data\" verfügbar\n",
    "# Überprüfe die tatsächlichen Spaltennamen in deinem DataFrame\n",
    "\n",
    "# Erstelle einen Reader für den Surprise-Datensatz\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Lade den DataFrame in einen Surprise-Datensatz\n",
    "data = Dataset.load_from_df(movie_data[['film', 'user', 'rating']], reader)\n",
    "\n",
    "# Teile den Datensatz in Trainings- und Testdaten auf\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'build_trainset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainset \u001b[39m=\u001b[39m netflix_data\u001b[39m.\u001b[39;49mbuild_trainset()\n\u001b[0;32m      2\u001b[0m testset \u001b[39m=\u001b[39m trainset\u001b[39m.\u001b[39mbuild_testset()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'build_trainset'"
     ]
    }
   ],
   "source": [
    "trainset = netflix_data.build_trainset()\n",
    "testset = trainset.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Gib Empfehlungen für Benutzer mit der ID 42 aus\n",
    "user_id = 42\n",
    "predictions = algo.test(testset)\n",
    "user_predictions = [pred for pred in predictions if pred[0] == user_id]\n",
    "top_n = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:10]\n",
    "for pred in top_n:\n",
    "    print(pred.iid, pred.est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m algo \u001b[39m=\u001b[39m KNNBasic(sim_options\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39muser_based\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m})\n\u001b[0;32m      4\u001b[0m \u001b[39m# Trainiere den Algorithmus mit den Trainingsdaten\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m algo\u001b[39m.\u001b[39mfit(trainset)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Lasse den Algorithmus Vorhersagen für die Testdaten machen\u001b[39;00m\n\u001b[0;32m      8\u001b[0m predictions \u001b[39m=\u001b[39m algo\u001b[39m.\u001b[39mtest(testset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "# Erstelle den KNN-Algorithmus\n",
    "algo = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "# Trainiere den Algorithmus mit den Trainingsdaten\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Lasse den Algorithmus Vorhersagen für die Testdaten machen\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Zeige einige Vorhersagen an\n",
    "for prediction in predictions[:5]:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'itertuples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m reader \u001b[39m=\u001b[39m Reader(rating_scale\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m     72\u001b[0m \u001b[39m# Lade den DataFrame in einen Surprise-Datensatz\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m data \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mload_from_df(ratings[[\u001b[39m'\u001b[39;49m\u001b[39mfilm\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m]], reader)\n\u001b[0;32m     75\u001b[0m \u001b[39m# Teile den Datensatz in Trainings- und Testdaten auf\u001b[39;00m\n\u001b[0;32m     76\u001b[0m trainset \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mbuild_full_trainset()\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\surprise\\dataset.py:167\u001b[0m, in \u001b[0;36mDataset.load_from_df\u001b[1;34m(cls, df, reader)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_df\u001b[39m(\u001b[39mcls\u001b[39m, df, reader):\n\u001b[0;32m    152\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a dataset from a pandas dataframe.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[39m    Use this if you want to use a custom dataset that is stored in a pandas\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39m            specified.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     \u001b[39mreturn\u001b[39;00m DatasetAutoFolds(reader\u001b[39m=\u001b[39;49mreader, df\u001b[39m=\u001b[39;49mdf)\n",
      "File \u001b[1;32mc:\\Users\\nabee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\surprise\\dataset.py:264\u001b[0m, in \u001b[0;36mDatasetAutoFolds.__init__\u001b[1;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39melif\u001b[39;00m df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m df\n\u001b[0;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_ratings \u001b[39m=\u001b[39m [\n\u001b[0;32m    263\u001b[0m         (uid, iid, \u001b[39mfloat\u001b[39m(r), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 264\u001b[0m         \u001b[39mfor\u001b[39;00m (uid, iid, r) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mitertuples(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    265\u001b[0m     ]\n\u001b[0;32m    266\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust specify ratings file or dataframe.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'itertuples'"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import json\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# small size for testing\n",
    "db_dev_path = 'netflix_dev.db'\n",
    "db_dev_conn = 'sqlite://' + db_dev_path\n",
    "\n",
    "# full size for production\n",
    "db_prod_path = 'netflix.db'\n",
    "db_prod_conn = 'sqlite://' + db_prod_path\n",
    "\n",
    "netflix_data = pl.read_database(\"SELECT * FROM netflix_data\", db_dev_conn)\n",
    "movie_titles = pl.read_database(\"SELECT * FROM movie_titles\", db_dev_conn)\n",
    "\n",
    "# the number of ratings\n",
    "len(netflix_data)\n",
    "\n",
    "# return the title for a given item_id (column film)\n",
    "# i.e. get_title(16242) -> \"Con Air\"\n",
    "def get_title(item_id):\n",
    "    return movie_titles.filter(pl.col(\"film\") == item_id)[\"title\"].to_list()[0]\n",
    "\n",
    "# remove movies with less than 100 ratings\n",
    "# get the number of ratings for each movie\n",
    "pre_ratings = netflix_data.groupby(\"film\").count()\n",
    "\n",
    "# keep only movies with at least 100 ratings\n",
    "pre_ratings = pre_ratings.filter(pl.col(\"count\") >= 200)\n",
    "\n",
    "# join the dataframes\n",
    "pre_ratings = netflix_data.join(pre_ratings, on=\"film\", how=\"inner\")\n",
    "\n",
    "# bring the ratings into a format that surprise can work with\n",
    "ratings = pre_ratings.drop(\"date\").drop(\"count\")\n",
    "ratings\n",
    "\n",
    "# average rating for each user\n",
    "avg_rating_user = ratings.groupby(\"user\").mean().sort(pl.col(\"rating\")).drop(\"film\")\n",
    "\n",
    "# average rating for each movie\n",
    "avg_rating_film = ratings.groupby(\"film\").mean().sort(pl.col(\"rating\")).drop(\"user\")\n",
    "\n",
    "# Count of ratings for each movie\n",
    "film_rating_counts = ratings.groupby(\"film\").agg(\n",
    "    [\n",
    "        pl.count(\"rating\").alias(\"count\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Count of ratings for each user\n",
    "user_rating_counts = ratings.groupby(\"user\").agg(\n",
    "    [\n",
    "        pl.count(\"rating\").alias(\"count\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "avg_rating_film = avg_rating_film.join(film_rating_counts, on=\"film\")\n",
    "avg_rating_user = avg_rating_user.join(user_rating_counts, on=\"user\")\n",
    "\n",
    "algo = KNNBasic()\n",
    "\n",
    "# Annahme: Der Netflix-Datensatz ist als DataFrame namens \"movie_data\" verfügbar\n",
    "# Überprüfe die tatsächlichen Spaltennamen in deinem DataFrame\n",
    "\n",
    "# Erstelle einen Reader für den Surprise-Datensatz\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Lade den DataFrame in einen Surprise-Datensatz\n",
    "data = Dataset.load_from_df(ratings[['film', 'user', 'rating']], reader)\n",
    "\n",
    "# Teile den Datensatz in Trainings- und Testdaten auf\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_testset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1468e071060>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Gib Empfehlungen für Benutzer mit der ID 42 aus\n",
    "user_id = 42\n",
    "predictions = algo.test(testset)\n",
    "user_predictions = [pred for pred in predictions if pred[0] == user_id]\n",
    "top_n = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:10]\n",
    "for pred in top_n:\n",
    "    print(pred.iid, pred.est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 15205      item: 2523958    r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 142234     r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 52203      r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 1091345    r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 1250371    r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# Erstelle den KNN-Algorithmus\n",
    "algo = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "# Trainiere den Algorithmus mit den Trainingsdaten\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Lasse den Algorithmus Vorhersagen für die Testdaten machen\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Zeige einige Vorhersagen an\n",
    "for prediction in predictions[:5]:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "#import json\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small size for testing\n",
    "db_dev_path = 'netflix_dev.db'\n",
    "db_dev_conn = 'sqlite://' + db_dev_path\n",
    "\n",
    "# full size for production\n",
    "db_prod_path = 'netflix.db'\n",
    "db_prod_conn = 'sqlite://' + db_prod_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data = pl.read_database(\"SELECT * FROM netflix_data\", db_dev_conn)\n",
    "movie_titles = pl.read_database(\"SELECT * FROM movie_titles\", db_dev_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove movies with less than 200 ratings\n",
    "# get the number of ratings for each movie\n",
    "pre_ratings = netflix_data.groupby(\"film\").count()\n",
    "\n",
    "# keep only movies with at least 200 ratings\n",
    "pre_ratings = pre_ratings.filter(pl.col(\"count\") >= 200)\n",
    "\n",
    "# join the dataframes\n",
    "pre_ratings = netflix_data.join(pre_ratings, on=\"film\", how=\"inner\")\n",
    "\n",
    "# bring the ratings into a format that surprise can work with\n",
    "ratings = pre_ratings.drop(\"date\").drop(\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the polars dataFrame to a pandas dataframe\n",
    "ratings_pandas = ratings.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reader for surprise dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# bring the dataframe to a surprise dataset\n",
    "data = Dataset.load_from_df(ratings_pandas[['film', 'user', 'rating']], reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train and a test data\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 15205      item: 2523958    r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 142234     r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 52203      r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 1091345    r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 1250371    r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# crete the KNN algorithm\n",
    "algo = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "# train the algorithm with train data\n",
    "algo.fit(trainset)\n",
    "\n",
    "# let the algorthm make some predictions \n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# show the predictions\n",
    "for prediction in predictions[:5]:\n",
    "    print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- user:        Die ID des Benutzers, für den die Vorhersage gemacht wurde.\n",
    "- item:     Die ID des Artikels (Films), für den die Vorhersage gemacht wurde.\n",
    "- r_ui:     Der tatsächliche Wert (Rating) des Benutzers für den Artikel in den Testdaten.\n",
    "- est:      Die vom Algorithmus vorhergesagte Bewertung für den Benutzer und den Artikel.\n",
    "- actual_k:         Die Anzahl der tatsächlich verwendeten Nachbarn (K) für die Vorhersage.\n",
    "- was_impossible:   Ein Flag, das angibt, ob die Vorhersage aufgrund von fehlenden Daten oder anderen Gründen unmöglich war."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give predictions for user_id = 42 as an example\n",
    "user_id = 387418\n",
    "user_predictions = [pred for pred in predictions if pred.uid == str(user_id)]\n",
    "top_n = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:10]\n",
    "for pred in top_n:\n",
    "    print(pred.iid, pred.est)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 15205      item: 2523958    r_ui = 4.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
      "user: 15205      item: 142234     r_ui = 3.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
      "user: 15205      item: 52203      r_ui = 3.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
      "user: 15205      item: 1091345    r_ui = 4.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
      "user: 15205      item: 1250371    r_ui = 3.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n"
     ]
    }
   ],
   "source": [
    "# change k\n",
    "min_k = 2  # least amount to be considered\n",
    "algo = KNNBasic(k=40, min_k=min_k, sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "k = 40  # number of neigbours\n",
    "\n",
    "\n",
    "# train the algo\n",
    "algo.fit(trainset)\n",
    "\n",
    "# let the algo predict\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# show the predictions\n",
    "for prediction in predictions[:5]:\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 15205      item: 2523958    r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 142234     r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 52203      r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 1091345    r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 1250371    r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# change k\n",
    "min_k = 2  # least amount to be considered\n",
    "sim_options = {\"name\": \"pearson_baseline\", \"shrinkage\": 0}  # no shrinkage\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "k = 40  # number of neigbours\n",
    "\n",
    "\n",
    "# train the algo\n",
    "algo.fit(trainset)\n",
    "\n",
    "# let the algo predict\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# show the predictions\n",
    "for prediction in predictions[:5]:\n",
    "    print(prediction)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigene ID bei Surprise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>count</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>387418</td><td>22</td></tr><tr><td>1461435</td><td>17</td></tr><tr><td>305344</td><td>15</td></tr><tr><td>2118461</td><td>15</td></tr><tr><td>2439493</td><td>14</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────┬───────┐\n",
       "│ user    ┆ count │\n",
       "│ ---     ┆ ---   │\n",
       "│ i64     ┆ u32   │\n",
       "╞═════════╪═══════╡\n",
       "│ 387418  ┆ 22    │\n",
       "│ 1461435 ┆ 17    │\n",
       "│ 305344  ┆ 15    │\n",
       "│ 2118461 ┆ 15    │\n",
       "│ 2439493 ┆ 14    │\n",
       "└─────────┴───────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating_counts = netflix_data.groupby(\"user\").count().sort(by=\"count\", descending=True)\n",
    "user_rating_counts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 15205      item: 2523958    r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 142234     r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 52203      r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 1091345    r_ui = 4.00   est = 4.00   {'actual_k': 1, 'was_impossible': False}\n",
      "user: 15205      item: 1250371    r_ui = 3.00   est = 3.00   {'actual_k': 1, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "'''import polars as pl\n",
    "import pandas as pd\n",
    "#import json\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# small size for testing\n",
    "db_dev_path = 'netflix_dev.db'\n",
    "db_dev_conn = 'sqlite://' + db_dev_path\n",
    "\n",
    "# full size for production\n",
    "db_prod_path = 'netflix.db'\n",
    "db_prod_conn = 'sqlite://' + db_prod_path\n",
    "\n",
    "netflix_data = pl.read_database(\"SELECT * FROM netflix_data\", db_dev_conn)\n",
    "movie_titles = pl.read_database(\"SELECT * FROM movie_titles\", db_dev_conn)\n",
    "\n",
    "# remove movies with less than 100 ratings\n",
    "# get the number of ratings for each movie\n",
    "pre_ratings = netflix_data.groupby(\"film\").count()\n",
    "\n",
    "# keep only movies with at least 100 ratings\n",
    "pre_ratings = pre_ratings.filter(pl.col(\"count\") >= 200)\n",
    "\n",
    "# join the dataframes\n",
    "pre_ratings = netflix_data.join(pre_ratings, on=\"film\", how=\"inner\")\n",
    "\n",
    "# bring the ratings into a format that surprise can work with\n",
    "ratings = pre_ratings.drop(\"date\").drop(\"count\")\n",
    "\n",
    "# Convert the polars dataFrame to a pandas dataframe\n",
    "ratings_pandas = ratings.to_pandas()\n",
    "\n",
    "# create a reader for surprise dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# bring the dataframe to a surprise dataset\n",
    "data = Dataset.load_from_df(ratings_pandas[['film', 'user', 'rating']], reader)\n",
    "\n",
    "# create a train and a test data\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "# crete the KNN algorithm\n",
    "algo = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "# train the algorithm with train data\n",
    "algo.fit(trainset)\n",
    "\n",
    "# let the algorthm make some predictions \n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# show the predictions\n",
    "for prediction in predictions[:5]:\n",
    "    print(prediction)\n",
    "\n",
    "# give predictions for user_id = 42 as an example\n",
    "user_id = 42\n",
    "user_predictions = [pred for pred in predictions if pred.uid == str(user_id)]\n",
    "top_n = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:10]\n",
    "for pred in top_n:\n",
    "    print(pred.iid, pred.est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "user: 15205      item: 2523958    r_ui = 4.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
      "user: 15205      item: 142234     r_ui = 3.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
      "user: 15205      item: 52203      r_ui = 3.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
      "user: 15205      item: 1091345    r_ui = 4.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n",
      "user: 15205      item: 1250371    r_ui = 3.00   est = 3.59   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n"
     ]
    }
   ],
   "source": [
    "'''# Erstelle den KNN-Algorithmus mit geänderter Anzahl der Nachbarn\n",
    "k = 5  # Anzahl der Nachbarn\n",
    "min_k = 2  # Mindestanzahl an Nachbarn für eine Vorhersage\n",
    "algo = KNNBasic(k=k, min_k=min_k, sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "# Trainiere den Algorithmus mit den Trainingsdaten\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Lasse den Algorithmus Vorhersagen für die Testdaten machen\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Zeige einige Vorhersagen an\n",
    "for prediction in predictions[:5]:\n",
    "    print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
