{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "Saving model with loss 0.10\n",
      "[Epoch 1] Test Loss: 2545.84 | Train Loss: 43.81 | Time: 340.56s | Top-500 Score: 0.09758955517150694\n",
      "Saving model with loss 0.11\n",
      "[Epoch 2] Test Loss: 948.36 | Train Loss: 34.70 | Time: 349.62s | Top-500 Score: 0.10775985574681766\n",
      "Saving model with loss 0.12\n",
      "[Epoch 3] Test Loss: 250.31 | Train Loss: 33.67 | Time: 354.08s | Top-500 Score: 0.1202464185670912\n",
      "Saving model with loss 0.12\n",
      "[Epoch 4] Test Loss: 412.24 | Train Loss: 33.16 | Time: 347.79s | Top-500 Score: 0.12446063778909824\n",
      "Saving model with loss 0.13\n",
      "[Epoch 5] Test Loss: 434.54 | Train Loss: 32.84 | Time: 350.85s | Top-500 Score: 0.13129307533801693\n",
      "[Epoch 6] Test Loss: 171.91 | Train Loss: 32.55 | Time: 337.88s | Top-500 Score: 0.12698164639012155\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import datetime as dt\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src import pipeline, models, training, evaluation\n",
    "from src.stopper import EarlyStopper\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "stopper = EarlyStopper(patience=5)\n",
    "data, movies = pipeline.clean_data()\n",
    "train, test = pipeline.split_data(data, dt.datetime(2005, 9, 1))\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.Autoencoder(len(movies)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "BATCH_SIZE = 128\n",
    "TOP_N_NUM = 500\n",
    "NOISING = True\n",
    "\n",
    "def apply_func_over_df(df, func, batch_size, shuffle, **kwargs):\n",
    "    current_index = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1)\n",
    "\n",
    "    while current_index < len(df):\n",
    "        batch_data = df.iloc[current_index:(current_index+batch_size)]\n",
    "        current_index += batch_size\n",
    "        total_loss += func(batch_data, **kwargs)\n",
    "    return total_loss\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    epoch_start = time.time()\n",
    "    model.train()\n",
    "    train_loss = apply_func_over_df(\n",
    "        df=train, \n",
    "        func=training.train_step, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        model=model, \n",
    "        optim=optimizer, \n",
    "        n_movies=len(movies), \n",
    "        device=device, \n",
    "        loss_fn=loss_fn,\n",
    "        noising=NOISING\n",
    "    )\n",
    "    model.eval()\n",
    "    test_loss = apply_func_over_df(\n",
    "        df=test, \n",
    "        func=training.test_step, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        model=model, \n",
    "        n_movies=len(movies), \n",
    "        device=device, \n",
    "        loss_fn=loss_fn\n",
    "    )\n",
    "\n",
    "    embeddings = evaluation.get_embeddings(len(movies), model, device)\n",
    "    top_n_score = apply_func_over_df(\n",
    "        df=test.iloc[:(len(test) // 20)],\n",
    "        func=evaluation.evaluate_batch,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        model=model,\n",
    "        n_recommendations=TOP_N_NUM,\n",
    "        device=device,\n",
    "        n_movies=len(movies),\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "    top_n_score /= (len(test) // 20)\n",
    "\n",
    "    if stopper.is_better(top_n_score):\n",
    "        print(f\"Saving model with loss {top_n_score:.2f}\")  \n",
    "        torch.save(model, 'model.pt')\n",
    "\n",
    "    if stopper.should_stop(top_n_score):\n",
    "        print(f\"Stopping early at epoch {epoch} with best score {stopper.best_score:.2f}\")\n",
    "        break\n",
    "\n",
    "    print(f'[Epoch {epoch}] Test Loss: {test_loss:.2f} | Train Loss: {train_loss:.2f} | Time: {time.time()-epoch_start:.2f}s | Top-{TOP_N_NUM} Score: {top_n_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1140655057553661"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopper.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
