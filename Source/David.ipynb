{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix recommendation engine\n",
    "\n",
    "Based on the [netflix prize dataset](https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data). Our\n",
    "goal is to build a recommendation engine.\n",
    "\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database\n",
    "\n",
    "Here we connect to the database `netflix_dev.db`. Currently, we are using a small portion of the whole dataset, around 100.000 / 100.000.000 Entries. This is due to the fact that the whole dataset is too big to be processed on a normal computer. We are using a sample of 100.000 entries to test our code and to get a first impression of the data. The sample is randomly chosen, so it is representative for the whole dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `netflix_data` contains the ratings from the netflix prize challenge.\n",
    "- `movie_titles` contains the titles corresponding to the `film` column in `netflix_data`\n",
    "- `combined` is a join of `netflix_data` and `movie_titles` over the `film` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'netflix_dev.db'\n",
    "db_conn = 'sqlite://' + db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data = pl.read_database(\"SELECT * FROM netflix_data\", db_conn)\n",
    "movie_titles = pl.read_database(\"SELECT * FROM movie_titles\", db_conn)\n",
    "combined     = pl.read_database(\"SELECT * FROM netflix_data, movie_titles \\\n",
    "                                  WHERE netflix_data.film = movie_titles.film\", db_conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some queries\n",
    "\n",
    "Now we run some queries on the data.\n",
    "- `most_rated` contains the 100 most rated movies.\n",
    "- `best_rated` contains the 100 best rated movies that have at least 50 ratings.\n",
    "- `not_rated` contains all movies that have no ratings.\n",
    "- `rated` contains all movies that have at least one rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_rated = pl.read_database(\"SELECT netflix_data.film, movie_titles.title, COUNT(*) AS 'num_ratings', AVG(netflix_data.rating) AS 'avg_rating' \\\n",
    "                               FROM netflix_data, movie_titles \\\n",
    "                               WHERE netflix_data.film = movie_titles.film \\\n",
    "                               GROUP BY netflix_data.film, title \\\n",
    "                               ORDER BY COUNT(*) DESC \\\n",
    "                               LIMIT 100 \\\n",
    "                               \", db_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rated = pl.read_database(\"SELECT netflix_data.film, movie_titles.title, COUNT(*) AS 'num_ratings', AVG(netflix_data.rating) AS 'avg_rating' \\\n",
    "                                FROM netflix_data, movie_titles \\\n",
    "                                WHERE netflix_data.film = movie_titles.film \\\n",
    "                                GROUP BY netflix_data.film, title \\\n",
    "                                HAVING num_ratings > 50 \\\n",
    "                                ORDER BY AVG(netflix_data.rating) DESC \\\n",
    "                                LIMIT 100\", db_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated = pl.read_database(\"SELECT movie_titles.film, movie_titles.title \\\n",
    "                          FROM movie_titles \\\n",
    "                          WHERE movie_titles.film IN (SELECT film FROM netflix_data)\",  db_conn)\n",
    "\n",
    "not_rated = pl.read_database(\"SELECT movie_titles.film, movie_titles.title \\\n",
    "                                FROM movie_titles \\\n",
    "                                WHERE movie_titles.film NOT IN (SELECT film FROM netflix_data)\",  db_conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a recommendation engine\n",
    "\n",
    "Now we create a recommendation engine. We use the `surprise` library for this. We use the `SVD` algorithm, which is a matrix factorization algorithm. We use the `trainset` to train the algorithm and the `testset` to test the algorithm. We use the `RMSE` as a metric to evaluate the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, KNNBasic, Reader, accuracy, SVD\n",
    "from surprise.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to bring the ratings data in the correct format. `Surprise` expects a dataframe of format `[user_ids, itemd_ids, ratings]`, so we need to drop the `date` column. We also need to convert the polars dataframe to a pandas dataframe, because surprise does not support polars dataframes. Finally, we can create the `Dataset` and the `trainset` and `testset` (75% training, 25% testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = netflix_data.drop(\"date\")\n",
    "ratings = ratings.to_pandas()\n",
    "\n",
    "data = Dataset.load_from_df(ratings, Reader(rating_scale=(1, 5)))\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "trainset_data = trainset.build_testset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the SVD algorithm and fit it to the dataset. Then we predict the ratings for the testset and calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2cd3c777df0>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 1.0415766256190409\n",
      "Mean Absolute Error (MAE): 0.8412969441935148\n"
     ]
    }
   ],
   "source": [
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = accuracy.rmse(predictions, verbose=False)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = accuracy.mae(predictions, verbose=False)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_predict():\n",
    "    # get two random indices from the trainset_data\n",
    "    i_1 = np.random.randint(0, len(trainset_data))\n",
    "    i_2 = np.random.randint(0, len(trainset_data))\n",
    "\n",
    "    # take the user_id from i_1\n",
    "    # take the item_id from i_2\n",
    "    user_id = trainset_data[i_1][1]\n",
    "    item_id = trainset_data[i_2][0]\n",
    "\n",
    "    # predict how user_id will rate item_id\n",
    "    pred = algo.predict(user_id, item_id)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print prediction information in a pretty string\n",
    "def pretty_predict(pred):\n",
    "    user_id = pred.uid\n",
    "    item_id = pred.iid\n",
    "    pred_rating = round(pred.est,2)\n",
    "    title = movie_titles.filter(pl.col(\"film\") == item_id)[\"title\"].to_list()[0]\n",
    "\n",
    "    print(\"User {0} will rate item {1} ({2}) with {3} stars.\".format(user_id, title, item_id, pred_rating))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict some ratings. Right now it returns ~3.6 stars almost every time (i dont know why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1567240 will rate item Friends: Season 6 (2942) with 3.61 stars.\n",
      "User 2566540 will rate item South Park: Season 5 (15609) with 3.61 stars.\n",
      "User 360287 will rate item White Men Can't Jump (12015) with 3.61 stars.\n",
      "User 829782 will rate item Sister Act (6386) with 3.61 stars.\n",
      "User 1178358 will rate item The Muppet Movie (16567) with 3.61 stars.\n",
      "User 2055183 will rate item Along Came a Spider (12299) with 3.61 stars.\n",
      "User 2488360 will rate item The Legend of Bagger Vance (10241) with 3.61 stars.\n",
      "User 1288043 will rate item The Patriot (14313) with 3.61 stars.\n",
      "User 2240832 will rate item The Four Seasons (3026) with 3.61 stars.\n",
      "User 719014 will rate item The Good Girl (12244) with 3.61 stars.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pred = random_predict()\n",
    "    pretty_predict(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
