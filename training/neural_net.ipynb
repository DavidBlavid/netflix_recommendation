{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import pipeline, model, training, data_containers\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 8192\n",
    "\n",
    "class EarlyStopper:\n",
    "\n",
    "    def __init__(self, patience: int):\n",
    "        self.patience_left = patience\n",
    "        self.patience = patience\n",
    "        self.best_loss = float(\"inf\")\n",
    "\n",
    "    def should_stop(self, loss: float) -> bool:\n",
    "        self.patience_left -= 1\n",
    "        if self.patience_left == 0:\n",
    "            return True\n",
    "        if loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.patience_left = self.patience\n",
    "        return False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "user_data, movies = pipeline.clean_data()\n",
    "formatted_user_data = training.format_user_data(user_data)\n",
    "train, test = training.train_test_split(formatted_user_data, 0.1)\n",
    "\n",
    "def calculate_loss(model_out: torch.Tensor, batch: data_containers.UserDataBatch, device: torch.device) -> torch.Tensor:\n",
    "    model_out = model_out*batch.relevancy_vector.to(device)\n",
    "    euclidian_distance = (model_out - batch.target_user_rating_vector.to(device))**2\n",
    "    loss = euclidian_distance.sum(dim=1) / batch.n_masked_ratings.to(device)\n",
    "    return loss.sum()\n",
    "\n",
    "for n_neurons in [2048]:\n",
    "    clf = model.Recommender(len(movies), n_neurons).to(device)\n",
    "    optim = torch.optim.Adam(clf.parameters(), lr=0.0001)\n",
    "    stopper = EarlyStopper(patience=5)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "\n",
    "    print(f\"Starting Training with {n_neurons} neurons...\")\n",
    "\n",
    "    for epoch in range(1, 100):\n",
    "        \n",
    "        train = train.sample(frac=1) # shuffle\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_test_loss = 0\n",
    "        current_index = 0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        while current_index < len(train):\n",
    "            batch_data = train.iloc[current_index:(current_index+BATCH_SIZE)]\n",
    "            current_index += BATCH_SIZE\n",
    "            \n",
    "\n",
    "            model_out = clf(batch.input_user_rating_vector.to(device))\n",
    "            loss = calculate_loss(model_out, batch, device)\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "\n",
    "        current_index = 0\n",
    "        clf.eval()\n",
    "        while current_index < len(test):\n",
    "            batch_data = test.iloc[current_index:(current_index+BATCH_SIZE)]\n",
    "            current_index += BATCH_SIZE\n",
    "            masked = batch_data.apply(lambda x: x.mask_values())\n",
    "            batch = training.masked_user_data_to_batch(masked, len(movies))\n",
    "            with torch.no_grad():\n",
    "                model_out = clf(batch.input_user_rating_vector.to(device))\n",
    "                loss = calculate_loss(model_out, batch, device)\n",
    "            total_test_loss += loss.item()\n",
    "        clf.train()\n",
    "\n",
    "        total_train_loss = round(total_train_loss / len(train), 6)\n",
    "        total_test_loss = round(total_test_loss / len(test), 6)\n",
    "\n",
    "        train_losses.append(total_train_loss)\n",
    "        test_losses.append(total_test_loss)\n",
    "\n",
    "        if total_test_loss < stopper.best_loss:\n",
    "             torch.save(clf, f\"model_{n_neurons}.pt\")\n",
    "\n",
    "        if stopper.should_stop(total_test_loss):\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "\n",
    "        epoch_time = int(time.time() - epoch_start)\n",
    "        print(f\"[EPOCH {epoch}] Total Training Loss: {total_train_loss} | Total Test Loss: {total_test_loss} | Time: {epoch_time}s\")\n",
    "    \n",
    "    np.save(f\"train_losses_{n_neurons}.npy\", np.array(train_losses))\n",
    "    np.save(f\"test_losses_{n_neurons}.npy\", np.array(test_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "Data cleaned!\n"
     ]
    }
   ],
   "source": [
    "from src import pipeline, model, training, data_containers\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 8192\n",
    "\n",
    "class EarlyStopper:\n",
    "\n",
    "    def __init__(self, patience: int):\n",
    "        self.patience_left = patience\n",
    "        self.patience = patience\n",
    "        self.best_loss = float(\"inf\")\n",
    "\n",
    "    def should_stop(self, loss: float) -> bool:\n",
    "        self.patience_left -= 1\n",
    "        if self.patience_left == 0:\n",
    "            return True\n",
    "        if loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            self.patience_left = self.patience\n",
    "        return False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "user_data, movies = pipeline.clean_data()\n",
    "formatted_user_data = training.format_user_data(user_data)\n",
    "train, test = training.train_test_split(formatted_user_data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>new_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2004</td>\n",
       "      <td>What the #$*! Do We Know!?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1994</td>\n",
       "      <td>Immortal Beloved</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>2002</td>\n",
       "      <td>Lilo and Stitch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>2003</td>\n",
       "      <td>Something's Gotta Give</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>1996</td>\n",
       "      <td>Dragonheart</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>17697</td>\n",
       "      <td>2004</td>\n",
       "      <td>New York Minute</td>\n",
       "      <td>2037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>17703</td>\n",
       "      <td>2003</td>\n",
       "      <td>Hulk</td>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>17709</td>\n",
       "      <td>1992</td>\n",
       "      <td>A River Runs Through It</td>\n",
       "      <td>2039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>17762</td>\n",
       "      <td>1997</td>\n",
       "      <td>Gattaca</td>\n",
       "      <td>2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>17764</td>\n",
       "      <td>1998</td>\n",
       "      <td>Shakespeare in Love</td>\n",
       "      <td>2041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2042 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       film  year                       title  new_id\n",
       "0         8  2004  What the #$*! Do We Know!?       0\n",
       "1        18  1994            Immortal Beloved       1\n",
       "2        28  2002             Lilo and Stitch       2\n",
       "3        30  2003      Something's Gotta Give       3\n",
       "4        58  1996                 Dragonheart       4\n",
       "...     ...   ...                         ...     ...\n",
       "2037  17697  2004             New York Minute    2037\n",
       "2038  17703  2003                        Hulk    2038\n",
       "2039  17709  1992     A River Runs Through It    2039\n",
       "2040  17762  1997                     Gattaca    2040\n",
       "2041  17764  1998         Shakespeare in Love    2041\n",
       "\n",
       "[2042 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_csv(\"movies.csv\", index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user = test.iloc[0]\n",
    "\n",
    "a = movies[movies[\"new_id\"].isin(sample_user.film_ids)]\n",
    "a[\"ratings\"] = sample_user.ratings\n",
    "\n",
    "vector = torch.zeros(1, len(movies))\n",
    "\n",
    "for _, row in a.iterrows():\n",
    "    vector[0, row[\"new_id\"]] = row[\"ratings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = torch.load(\"runs/model_4096.pt\")\n",
    "\n",
    "clf.eval()\n",
    "\n",
    "a = clf(vector.to(device)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = torch.load(\"runs/model_4096.pt\")\n",
    "\n",
    "clf.eval()\n",
    "\n",
    "lilo_and_stitch = torch.zeros(1, len(movies))\n",
    "lilo_and_stitch[0, 1264] = 1\n",
    "\n",
    "a = clf(lilo_and_stitch.to(device)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data1 = np.load(\"runs/test_losses_512.npy\")\n",
    "data2 = np.load(\"runs/test_losses_1024.npy\")\n",
    "data3 = np.load(\"runs/test_losses_2048.npy\")\n",
    "data4 = np.load(\"runs/test_losses_4096.npy\")\n",
    "data5 = np.load(\"runs/test_losses_8192.npy\")\n",
    "\n",
    "\n",
    "data_1 = [(i, l, 512) for i, l in enumerate(data1, start=1)]\n",
    "data_2 = [(i, l, 1024) for i, l in enumerate(data2, start=1)]\n",
    "data_3 = [(i, l, 2048) for i, l in enumerate(data3, start=1)]\n",
    "data_4 = [(i, l, 4096) for i, l in enumerate(data4, start=1)]\n",
    "data_5 = [(i, l, 8192) for i, l in enumerate(data5, start=1)]\n",
    "\n",
    "\n",
    "data = data_1 + data_2 + data_3 + data_5\n",
    "data = pd.DataFrame(data, columns=[\"epoch\", \"loss\", \"neurons\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "clf = torch.load(\"runs/model_8192.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "fig = px.line(\n",
    "    data,\n",
    "    x=\"epoch\",\n",
    "    y=\"loss\",\n",
    "    color=\"neurons\",\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.argsort(a[0])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.query(\"new_id == 781\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies[\"title\"].str.contains(\"Star Wars\")]628,945,994,1097,1120,1860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\johnn\\Desktop\\netflix_recommendation\\Source\\data\\movie_data.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "image_url = \"https://www.imdb.com/title/tt0399877/mediaviewer/rm1940363520/?ref_=tt_ov_i\"\n",
    "\n",
    "#download image from url and save to disk\n",
    "img_data = requests.get(image_url).content\n",
    "with open('image_name.jpg', 'wb') as handler:\n",
    "    handler.write(img_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"https://www.imdb.com/title/tt0121765/\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recommender(\n",
       "  (inp): Linear(in_features=2042, out_features=8192, bias=True)\n",
       "  (inp_bn): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inp_relu): LeakyReLU(negative_slope=0.01)\n",
       "  (hidden1): Linear(in_features=8192, out_features=8192, bias=True)\n",
       "  (bn1): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (hidden2): Linear(in_features=8192, out_features=8192, bias=True)\n",
       "  (bn2): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): LeakyReLU(negative_slope=0.01)\n",
       "  (hidden3): Linear(in_features=8192, out_features=8192, bias=True)\n",
       "  (bn3): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (outp): Linear(in_features=8192, out_features=2042, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "request_json = {\"ratings\": [\n",
    "    {\"movieId\": 1, \"rating\": 5},\n",
    "    {\"movieId\": 2, \"rating\": 3},\n",
    "    {\"movieId\": 3, \"rating\": 4}\n",
    "]}\n",
    "\n",
    "import torch\n",
    "\n",
    "model = torch.load(\"model_8192.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = torch.zeros(1, 2042).to(\"cuda\")\n",
    "avg_rating = sum([r[\"rating\"] for r in request_json[\"ratings\"]]) / len(request_json[\"ratings\"])\n",
    "for rating in request_json[\"ratings\"]:\n",
    "    vec[0, rating[\"movieId\"]] = (rating[\"rating\"] - avg_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions_ordered = np.argsort(preds[0].detach().cpu().numpy())\n",
    "predictions_ordered = predictions_ordered[-(9+len(request_json[\"ratings\"])):]\n",
    "without_input_movies = [p for p in predictions_ordered if p not in [r[\"movieId\"] for r in request_json[\"ratings\"]]][-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[888, 939, 1072, 877, 1028, 422, 1783, 930, 408]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_input_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
