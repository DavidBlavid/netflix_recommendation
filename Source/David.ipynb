{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix recommendation engine\n",
    "\n",
    "Based on the [netflix prize dataset](https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data). Our\n",
    "goal is to build a recommendation engine.\n",
    "\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import sqlite3\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database\n",
    "\n",
    "Here we connect to the database `netflix_dev.db`. Currently, we are using a small portion of the whole dataset, around 100.000 / 100.000.000 Entries. This is due to the fact that the whole dataset is too big to be processed on a normal computer. We are using a sample of 100.000 entries to test our code and to get a first impression of the data. The sample is randomly chosen, so it is representative for the whole dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `netflix_data` contains the ratings from the netflix prize challenge.\n",
    "- `movie_titles` contains the titles corresponding to the `film` column in `netflix_data`\n",
    "- `combined` is a join of `netflix_data` and `movie_titles` over the `film` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'netflix_dev.db'\n",
    "db_conn = 'sqlite://' + db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data = pl.read_database(\"SELECT * FROM netflix_data\", db_conn)\n",
    "movie_titles = pl.read_database(\"SELECT * FROM movie_titles\", db_conn)\n",
    "combined     = pl.read_database(\"SELECT * FROM netflix_data, movie_titles \\\n",
    "                                  WHERE netflix_data.film = movie_titles.film\", db_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the title for a given item_id (column film)\n",
    "# i.e. get_title(16242) -> \"Con Air\"\n",
    "def get_title(item_id):\n",
    "    return movie_titles.filter(pl.col(\"film\") == item_id)[\"title\"].to_list()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some queries\n",
    "\n",
    "Now we run some queries on the data.\n",
    "- `most_rated` contains the 100 most rated movies.\n",
    "- `best_rated` contains the 100 best rated movies that have at least 50 ratings.\n",
    "- `not_rated` contains all movies that have no ratings.\n",
    "- `rated` contains all movies that have at least one rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>film</th><th>title</th><th>num_ratings</th><th>avg_rating</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>5317</td><td>&quot;Miss Congenial…</td><td>233</td><td>3.549356</td></tr><tr><td>15124</td><td>&quot;Independence D…</td><td>220</td><td>3.736364</td></tr><tr><td>15205</td><td>&quot;The Day After …</td><td>212</td><td>3.476415</td></tr><tr><td>11283</td><td>&quot;Forrest Gump&quot;</td><td>199</td><td>4.351759</td></tr><tr><td>16242</td><td>&quot;Con Air&quot;</td><td>196</td><td>3.377551</td></tr><tr><td>15582</td><td>&quot;Sweet Home Ala…</td><td>191</td><td>3.507853</td></tr><tr><td>6287</td><td>&quot;Pretty Woman&quot;</td><td>190</td><td>3.884211</td></tr><tr><td>6972</td><td>&quot;Armageddon&quot;</td><td>186</td><td>3.5</td></tr><tr><td>14313</td><td>&quot;The Patriot&quot;</td><td>184</td><td>3.869565</td></tr><tr><td>1905</td><td>&quot;Pirates of the…</td><td>183</td><td>4.245902</td></tr><tr><td>1962</td><td>&quot;50 First Dates…</td><td>178</td><td>3.780899</td></tr><tr><td>4432</td><td>&quot;The Italian Jo…</td><td>172</td><td>3.767442</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>11337</td><td>&quot;American Pie&quot;</td><td>120</td><td>3.675</td></tr><tr><td>12293</td><td>&quot;The Godfather&quot;</td><td>120</td><td>4.5</td></tr><tr><td>12338</td><td>&quot;Harry Potter a…</td><td>120</td><td>4.208333</td></tr><tr><td>12966</td><td>&quot;The Aviator&quot;</td><td>120</td><td>3.5</td></tr><tr><td>14660</td><td>&quot;The Waterboy&quot;</td><td>120</td><td>3.358333</td></tr><tr><td>5085</td><td>&quot;Seabiscuit&quot;</td><td>119</td><td>4.033613</td></tr><tr><td>8387</td><td>&quot;Minority Repor…</td><td>119</td><td>3.554622</td></tr><tr><td>8904</td><td>&quot;Good Will Hunt…</td><td>119</td><td>4.294118</td></tr><tr><td>13462</td><td>&quot;The General&#x27;s …</td><td>119</td><td>3.268908</td></tr><tr><td>1307</td><td>&quot;S.W.A.T.&quot;</td><td>118</td><td>3.322034</td></tr><tr><td>3151</td><td>&quot;Napoleon Dynam…</td><td>118</td><td>3.381356</td></tr><tr><td>8644</td><td>&quot;Catch Me If Yo…</td><td>118</td><td>3.771186</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 4)\n",
       "┌───────┬────────────────────────┬─────────────┬────────────┐\n",
       "│ film  ┆ title                  ┆ num_ratings ┆ avg_rating │\n",
       "│ ---   ┆ ---                    ┆ ---         ┆ ---        │\n",
       "│ i64   ┆ str                    ┆ i64         ┆ f64        │\n",
       "╞═══════╪════════════════════════╪═════════════╪════════════╡\n",
       "│ 5317  ┆ Miss Congeniality      ┆ 233         ┆ 3.549356   │\n",
       "│ 15124 ┆ Independence Day       ┆ 220         ┆ 3.736364   │\n",
       "│ 15205 ┆ The Day After Tomorrow ┆ 212         ┆ 3.476415   │\n",
       "│ 11283 ┆ Forrest Gump           ┆ 199         ┆ 4.351759   │\n",
       "│ …     ┆ …                      ┆ …           ┆ …          │\n",
       "│ 13462 ┆ The General's Daughter ┆ 119         ┆ 3.268908   │\n",
       "│ 1307  ┆ S.W.A.T.               ┆ 118         ┆ 3.322034   │\n",
       "│ 3151  ┆ Napoleon Dynamite      ┆ 118         ┆ 3.381356   │\n",
       "│ 8644  ┆ Catch Me If You Can    ┆ 118         ┆ 3.771186   │\n",
       "└───────┴────────────────────────┴─────────────┴────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_rated = pl.read_database(\"SELECT netflix_data.film, movie_titles.title, COUNT(*) AS 'num_ratings', AVG(netflix_data.rating) AS 'avg_rating' \\\n",
    "                               FROM netflix_data, movie_titles \\\n",
    "                               WHERE netflix_data.film = movie_titles.film \\\n",
    "                               GROUP BY netflix_data.film, title \\\n",
    "                               ORDER BY COUNT(*) DESC \\\n",
    "                               LIMIT 100 \\\n",
    "                               \", db_conn)\n",
    "\n",
    "most_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>film</th><th>title</th><th>num_ratings</th><th>avg_rating</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>14961</td><td>&quot;Lord of the Ri…</td><td>83</td><td>4.759036</td></tr><tr><td>5582</td><td>&quot;Star Wars: Epi…</td><td>98</td><td>4.704082</td></tr><tr><td>7230</td><td>&quot;The Lord of th…</td><td>74</td><td>4.702703</td></tr><tr><td>7057</td><td>&quot;Lord of the Ri…</td><td>75</td><td>4.626667</td></tr><tr><td>16265</td><td>&quot;Star Wars: Epi…</td><td>89</td><td>4.58427</td></tr><tr><td>14550</td><td>&quot;The Shawshank …</td><td>151</td><td>4.576159</td></tr><tr><td>9628</td><td>&quot;Star Wars: Epi…</td><td>84</td><td>4.559524</td></tr><tr><td>14240</td><td>&quot;Lord of the Ri…</td><td>140</td><td>4.557143</td></tr><tr><td>10042</td><td>&quot;Raiders of the…</td><td>108</td><td>4.509259</td></tr><tr><td>12293</td><td>&quot;The Godfather&quot;</td><td>120</td><td>4.5</td></tr><tr><td>12870</td><td>&quot;Schindler&#x27;s Li…</td><td>93</td><td>4.494624</td></tr><tr><td>5561</td><td>&quot;Cool Hand Luke…</td><td>54</td><td>4.444444</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>11443</td><td>&quot;Harry Potter a…</td><td>97</td><td>4.030928</td></tr><tr><td>17324</td><td>&quot;Hitch&quot;</td><td>106</td><td>4.028302</td></tr><tr><td>5926</td><td>&quot;Fight Club&quot;</td><td>109</td><td>4.027523</td></tr><tr><td>16223</td><td>&quot;Vertigo&quot;</td><td>51</td><td>4.019608</td></tr><tr><td>886</td><td>&quot;Ray&quot;</td><td>105</td><td>4.019048</td></tr><tr><td>9189</td><td>&quot;Crimson Tide&quot;</td><td>61</td><td>4.016393</td></tr><tr><td>10607</td><td>&quot;We Were Soldie…</td><td>67</td><td>4.014925</td></tr><tr><td>3624</td><td>&quot;The Last Samur…</td><td>139</td><td>4.014388</td></tr><tr><td>7511</td><td>&quot;Blade&quot;</td><td>72</td><td>4.013889</td></tr><tr><td>8915</td><td>&quot;Terminator 2: …</td><td>76</td><td>4.013158</td></tr><tr><td>13302</td><td>&quot;Blazing Saddle…</td><td>78</td><td>4.012821</td></tr><tr><td>571</td><td>&quot;American Beaut…</td><td>160</td><td>4.0125</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 4)\n",
       "┌───────┬───────────────────────────────────┬─────────────┬────────────┐\n",
       "│ film  ┆ title                             ┆ num_ratings ┆ avg_rating │\n",
       "│ ---   ┆ ---                               ┆ ---         ┆ ---        │\n",
       "│ i64   ┆ str                               ┆ i64         ┆ f64        │\n",
       "╞═══════╪═══════════════════════════════════╪═════════════╪════════════╡\n",
       "│ 14961 ┆ Lord of the Rings: The Return of… ┆ 83          ┆ 4.759036   │\n",
       "│ 5582  ┆ Star Wars: Episode V: The Empire… ┆ 98          ┆ 4.704082   │\n",
       "│ 7230  ┆ The Lord of the Rings: The Fello… ┆ 74          ┆ 4.702703   │\n",
       "│ 7057  ┆ Lord of the Rings: The Two Tower… ┆ 75          ┆ 4.626667   │\n",
       "│ …     ┆ …                                 ┆ …           ┆ …          │\n",
       "│ 7511  ┆ Blade                             ┆ 72          ┆ 4.013889   │\n",
       "│ 8915  ┆ Terminator 2: Extreme Edition     ┆ 76          ┆ 4.013158   │\n",
       "│ 13302 ┆ Blazing Saddles                   ┆ 78          ┆ 4.012821   │\n",
       "│ 571   ┆ American Beauty                   ┆ 160         ┆ 4.0125     │\n",
       "└───────┴───────────────────────────────────┴─────────────┴────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rated = pl.read_database(\"SELECT netflix_data.film, movie_titles.title, COUNT(*) AS 'num_ratings', AVG(netflix_data.rating) AS 'avg_rating' \\\n",
    "                                FROM netflix_data, movie_titles \\\n",
    "                                WHERE netflix_data.film = movie_titles.film \\\n",
    "                                GROUP BY netflix_data.film, title \\\n",
    "                                HAVING num_ratings > 50 \\\n",
    "                                ORDER BY AVG(netflix_data.rating) DESC \\\n",
    "                                LIMIT 100\", db_conn)\n",
    "\n",
    "best_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9_235, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>film</th><th>title</th></tr><tr><td>i64</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Dinosaur Plane…</td></tr><tr><td>2</td><td>&quot;Isle of Man TT…</td></tr><tr><td>3</td><td>&quot;Character&quot;</td></tr><tr><td>6</td><td>&quot;Sick&quot;</td></tr><tr><td>8</td><td>&quot;What the #$*! …</td></tr><tr><td>10</td><td>&quot;Fighter&quot;</td></tr><tr><td>12</td><td>&quot;My Favorite Br…</td></tr><tr><td>13</td><td>&quot;Lord of the Ri…</td></tr><tr><td>15</td><td>&quot;Neil Diamond: …</td></tr><tr><td>16</td><td>&quot;Screamers&quot;</td></tr><tr><td>17</td><td>&quot;7 Seconds&quot;</td></tr><tr><td>18</td><td>&quot;Immortal Belov…</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>17754</td><td>&quot;On the Ropes&quot;</td></tr><tr><td>17756</td><td>&quot;The 39 Steps&quot;</td></tr><tr><td>17758</td><td>&quot;Prophecy&quot;</td></tr><tr><td>17759</td><td>&quot;The Big Bird C…</td></tr><tr><td>17761</td><td>&quot;Levity&quot;</td></tr><tr><td>17762</td><td>&quot;Gattaca&quot;</td></tr><tr><td>17763</td><td>&quot;Interiors&quot;</td></tr><tr><td>17764</td><td>&quot;Shakespeare in…</td></tr><tr><td>17767</td><td>&quot;Fidel Castro: …</td></tr><tr><td>17768</td><td>&quot;Epoch&quot;</td></tr><tr><td>17769</td><td>&quot;The Company&quot;</td></tr><tr><td>17770</td><td>&quot;Alien Hunter&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9_235, 2)\n",
       "┌───────┬───────────────────────────────────┐\n",
       "│ film  ┆ title                             │\n",
       "│ ---   ┆ ---                               │\n",
       "│ i64   ┆ str                               │\n",
       "╞═══════╪═══════════════════════════════════╡\n",
       "│ 1     ┆ Dinosaur Planet                   │\n",
       "│ 2     ┆ Isle of Man TT 2004 Review        │\n",
       "│ 3     ┆ Character                         │\n",
       "│ 6     ┆ Sick                              │\n",
       "│ …     ┆ …                                 │\n",
       "│ 17767 ┆ Fidel Castro: American Experienc… │\n",
       "│ 17768 ┆ Epoch                             │\n",
       "│ 17769 ┆ The Company                       │\n",
       "│ 17770 ┆ Alien Hunter                      │\n",
       "└───────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rated = pl.read_database(\"SELECT movie_titles.film, movie_titles.title \\\n",
    "                          FROM movie_titles \\\n",
    "                          WHERE movie_titles.film IN (SELECT film FROM netflix_data)\",  db_conn)\n",
    "\n",
    "not_rated = pl.read_database(\"SELECT movie_titles.film, movie_titles.title \\\n",
    "                              FROM movie_titles \\\n",
    "                              WHERE movie_titles.film NOT IN (SELECT film FROM netflix_data)\",  db_conn)\n",
    "\n",
    "rated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the movie metadata\n",
    "\n",
    "We use the [OMDb API](http://www.omdbapi.com/) to get the movie metadata. We use the `film` from the `movie_titles` table to get the metadata for each movie. We store the metadata in the `movie_metadata` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PLEASE DELETE BEFORE PUBLIC RELEASE\n",
    "api_key = \"put api key here\"\n",
    "\n",
    "# get movie data from the omdb api\n",
    "#\n",
    "# input: title of movie (str)\n",
    "#\n",
    "# output: json object of movie data\n",
    "#         title, year, rated, release date, runtime, genre, language, country, ratings from different sites, ...\n",
    "def ombd_api(title):\n",
    "\n",
    "    url = \"http://www.omdbapi.com/?apikey=\" + api_key + \"&t=\" + title\n",
    "    response = requests.get(url)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get the movie metadata for every single movie. First, we get all movie titles from the `movie_titles` table. Then we iterate over the movie titles and get the metadata for each movie. We store the metadata in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    'Year',\n",
    "    'Response',\n",
    "    'Rated',\n",
    "    'Released',\n",
    "    'Runtime',\n",
    "    'Genre',\n",
    "    'Director',\n",
    "    'Writer',\n",
    "    'Actors',\n",
    "    'Plot',\n",
    "    'Language',\n",
    "    'Country',\n",
    "    'Awards',\n",
    "    'Poster',\n",
    "    'Ratings',\n",
    "    'Metascore',\n",
    "    'imdbRating',\n",
    "    'imdbVotes',\n",
    "    'imdbID',\n",
    "    'Type',\n",
    "    'DVD',\n",
    "    'BoxOffice',\n",
    "    'Production',\n",
    "    'Website',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9235/9235 [1:06:59<00:00,  2.30it/s] \n"
     ]
    }
   ],
   "source": [
    "# CAN BE SKIPPED\n",
    "titles = rated[\"title\"].to_list()\n",
    "\n",
    "# get movie data for all rated movies\n",
    "movie_data = []\n",
    "\n",
    "for title in tqdm(titles):\n",
    "\n",
    "    response = ombd_api(title)\n",
    "    current_data = {}\n",
    "\n",
    "    # try to copy all value to all fields\n",
    "    for field in fields:\n",
    "\n",
    "        current_data[\"Title\"] = title\n",
    "\n",
    "        # is the current field in the response?\n",
    "        # if yes -> copy the value from the response\n",
    "        # if no  -> set the value to \"N/A\"\n",
    "        if(field not in response):\n",
    "            current_data[field] = \"N/A\"\n",
    "        else:\n",
    "            current_data[field] = response.get(field)\n",
    "\n",
    "    movie_data.append(current_data)\n",
    "\n",
    "    sleep(0.1)\n",
    "\n",
    "df = pd.DataFrame(movie_data)\n",
    "df.to_csv(\"/data/movie_data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a recommendation engine\n",
    "\n",
    "Now we create a recommendation engine. We use the `surprise` library for this. We use the `SVD` algorithm, which is a matrix factorization algorithm. We use the `trainset` to train the algorithm and the `testset` to test the algorithm. We use the `RMSE` as a metric to evaluate the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, KNNBasic, Reader, accuracy, SVD\n",
    "from surprise.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to bring the ratings data in the correct format. `Surprise` expects a dataframe of format `[user_ids, itemd_ids, ratings]`, so we need to drop the `date` column. We also need to convert the polars dataframe to a pandas dataframe, because surprise does not support polars dataframes. Finally, we can create the `Dataset` and the `trainset` and `testset` (75% training, 25% testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = netflix_data.drop(\"date\")\n",
    "ratings = ratings.to_pandas()\n",
    "\n",
    "data = Dataset.load_from_df(ratings, Reader(rating_scale=(1, 5)))\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "trainset_data = trainset.build_testset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the SVD algorithm and fit it to the dataset. Then we predict the ratings for the testset and calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1d076218a30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 1.0399204120378003\n",
      "Mean Absolute Error (MAE): 0.8400388009536006\n"
     ]
    }
   ],
   "source": [
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = accuracy.rmse(predictions, verbose=False)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = accuracy.mae(predictions, verbose=False)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_predict():\n",
    "    # get two random indices from the trainset_data\n",
    "    i_1 = np.random.randint(0, len(trainset_data))\n",
    "    i_2 = np.random.randint(0, len(trainset_data))\n",
    "\n",
    "    # take the user_id from i_1\n",
    "    # take the item_id from i_2\n",
    "    user_id = trainset_data[i_1][1]\n",
    "    item_id = trainset_data[i_2][0]\n",
    "\n",
    "    # predict how user_id will rate item_id\n",
    "    pred = algo.predict(user_id, item_id)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print prediction information in a pretty string\n",
    "def pretty_predict(pred):\n",
    "    user_id = pred.uid\n",
    "    item_id = pred.iid\n",
    "    pred_rating = pred.est\n",
    "    title = get_title(item_id)\n",
    "\n",
    "    print(\"User {0} will rate {1} ({2}) with {3} stars.\".format(user_id, title, item_id, pred_rating))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict some ratings. Right now it returns ~3.6 stars almost every time (i dont know why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2519375 will rate Waiting for Guffman (16201) with 3.6043866666666666 stars.\n",
      "User 647602 will rate The Princess Diaries (Widescreen) (11265) with 3.6043866666666666 stars.\n",
      "User 2016590 will rate Kiss: Exposed (2092) with 3.6043866666666666 stars.\n",
      "User 132059 will rate Two Weeks Notice (13050) with 3.6043866666666666 stars.\n",
      "User 306199 will rate The Flamingo Kid (8254) with 3.6043866666666666 stars.\n",
      "User 2509503 will rate The Notebook (14103) with 3.6043866666666666 stars.\n",
      "User 2587117 will rate Jerry Maguire (13763) with 3.6043866666666666 stars.\n",
      "User 2556053 will rate Big Momma's House (6347) with 3.6043866666666666 stars.\n",
      "User 1284226 will rate Just Married (10921) with 3.6043866666666666 stars.\n",
      "User 2366006 will rate The Verdict (12593) with 3.6043866666666666 stars.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pred = random_predict()\n",
    "    pretty_predict(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baby Shakespeare: World of Poetry (7133) - 3.8561833188464307 stars\n",
      "Slums of Beverly Hills (15181) - 3.8418737428628598 stars\n",
      "Latin Kings: A Street Gang Story (6663) - 3.8088334610349937 stars\n",
      "Moonlight Mile (7363) - 3.8007843140571373 stars\n",
      "Amelie: Bonus Material (15865) - 3.793172170972907 stars\n",
      "Renegades (17587) - 3.780581995056136 stars\n",
      "The SoulTaker (192) - 3.7706913354987903 stars\n",
      "Lost: Season 1 (3456) - 3.7587480937264806 stars\n",
      "Stargate SG-1: Season 1 (14363) - 3.7496374742696768 stars\n",
      "Wiseguy: Season 1: Part 2 (6504) - 3.7459049147798718 stars\n"
     ]
    }
   ],
   "source": [
    "# rate all movies for a given user_id\n",
    "user_id = 517756\n",
    "\n",
    "# get all the item_ids in the trainset_data\n",
    "item_ids = [x[0] for x in trainset_data]\n",
    "\n",
    "# item_ids should only be unique values\n",
    "item_ids = list(set(item_ids))\n",
    "\n",
    "# get a rating for all item_ids from user_id\n",
    "user_ratings = {}\n",
    "for item_id in item_ids:\n",
    "    pred = algo.predict(user_id, item_id)\n",
    "    user_ratings[item_id] = pred.est\n",
    "\n",
    "# sort the ratings from highest to lowest\n",
    "user_ratings = sorted(user_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print the top 10 movies for user_id\n",
    "for item_id, rating in user_ratings[:10]:\n",
    "    title = get_title(item_id)\n",
    "    print(\"{0} ({1}) - {2} stars\".format(title, item_id, rating))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
